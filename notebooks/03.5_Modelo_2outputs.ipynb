{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d-ZMY-P4aSg"
   },
   "source": [
    "# 03.5_Modelo_2outputs\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "Entrenar y comparar modelos de clasificación binaria (`Logistic Regression`, `RandomForest` y `GradientBoosting`) a partir de las cuatro categorías de riesgo originales, remapeadas a dos clases (`bajo/medio` vs. `alto`). Se busca evaluar distintas estrategias de ajuste de umbral para priorizar la detección de alto riesgo o la protección de bajo riesgo, **sin aplicar SMOTE** y utilizando `class_weight='balanced'`.\n",
    "\n",
    "## Entradas (Inputs)\n",
    "- `data/splits/experiments/X_train_17.parquet`\n",
    "- `data/splits/experiments/X_val_17.parquet`\n",
    "- `data/splits/experiments/X_test_17.parquet`\n",
    "- `data/splits/final/y_train.parquet`\n",
    "- `data/splits/final/y_val.parquet`\n",
    "- `data/splits/final/y_test.parquet`\n",
    "\n",
    "## Salidas (Outputs)\n",
    "- `data/splits/final/y_train_2_classes.parquet`\n",
    "- `data/splits/final/y_val_2_classes.parquet`\n",
    "- `data/splits/final/y_test_2_classes.parquet`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GV4k7EH-kTVz"
   },
   "source": [
    "## Resumen Ejecutivo\n",
    "- Este notebook entrena y compara tres modelos de clasificación binaria (Regresión Logística, Random Forest y Gradient Boosting) sobre los datos remapeados a dos clases (bajo vs. alto riesgo), sin aplicar SMOTE y empleando `class_weight='balanced'`.  \n",
    "- Se cargan los splits entrenados con 17 variables sintéticas y se remapean las etiquetas originales a dos categorías (`y_*_2`).  \n",
    "- Se definen pipelines de preprocesamiento (`StandardScaler`) y clasificador para cada algoritmo.  \n",
    "- Se implementa la función `evaluate_binary_realistic` para calcular accuracy, F1 y AUC realista, mostrando además las matrices de confusión.  \n",
    "- Se ajustan dos umbrales específicos para Random Forest:  \n",
    "  1. **Detector de Alto Riesgo** (maximiza detección de clase alta)  \n",
    "  2. **Protector de Bajo Riesgo** (minimiza errores en clase baja)  \n",
    "- Regresión Logística y Gradient Boosting se evalúan con umbral 0.5; Random Forest con los umbrales optimizados en validación.  \n",
    "- La comparación en validación y test evidencia cómo cada modelo y estrategia de threshold impacta precision/recall de cada clase.  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3Yu4JyY9F_v"
   },
   "source": [
    "## 1. Configuración de entorno local, importar librerías y cargar configuración\n",
    "\n",
    "Esta celda monta Google Drive, importa y organiza las librerías necesarias (estándar, terceros y locales), añade la raíz del proyecto al `sys.path` y carga las rutas de configuración para los directorios de splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27958,
     "status": "ok",
     "timestamp": 1749634190905,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "igMYA3hO2ByJ",
    "outputId": "41a30946-65c0-4bd0-b154-325f5dca5ec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Módulo de configuración cargado y estructura de carpetas asegurada.\n",
      "Drive montado, librerías importadas y configuración de rutas cargada.\n",
      "Directorio de splits experimentales: C:\\Users\\Antonio\\TFM-Digitech\\data\\splits\\experiments\n",
      "Directorio de splits finales (para 'y' originales): C:\\Users\\Antonio\\TFM-Digitech\\data\\splits\\final\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Añadir la raíz del proyecto al path\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent if current_dir.name == 'notebooks' else current_dir\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# 3. Importar las rutas necesarias desde el archivo de configuración\n",
    "from config import FINAL_SPLITS_DIR, EXP_SPLITS_DIR\n",
    "\n",
    "print(\"Drive montado, librerías importadas y configuración de rutas cargada.\")\n",
    "print(f\"Directorio de splits experimentales: {EXP_SPLITS_DIR}\")\n",
    "print(f\"Directorio de splits finales (para 'y' originales): {FINAL_SPLITS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtYiCier9Hym"
   },
   "source": [
    "## 2. Cargar conjuntos de datos desde archivos Parquet\n",
    "\n",
    "Esta celda carga los conjuntos de datos sintéticos de entrenamiento desde archivos Parquet ubicados en `EXP_SPLITS_DIR`, manejando excepciones si no se encuentran.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2555,
     "status": "ok",
     "timestamp": 1749634193466,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "19t1Cwkt2Bjz",
    "outputId": "ca6fb76c-3975-449f-88f3-1a8b51902b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos .parquet cargados correctamente.\n",
      "\n",
      " Shapes tras cargar splits:\n",
      "   • X_train_sint: (1976, 14), y_train: (1976,)\n",
      "   • X_val_sint:   (424, 14),   y_val:   (424,)\n",
      "   • X_test_sint:  (424, 14),  y_test:  (424,)\n"
     ]
    }
   ],
   "source": [
    "# CARGAR LOS CONJUNTOS DE DATOS\n",
    "\n",
    "try:\n",
    "    # Las 'X' con 17 features vienen del experimento anterior (03.4)\n",
    "    X_train_sint = pd.read_parquet(EXP_SPLITS_DIR / 'X_train_17.parquet')\n",
    "    X_val_sint   = pd.read_parquet(EXP_SPLITS_DIR / 'X_val_17.parquet')\n",
    "    X_test_sint  = pd.read_parquet(EXP_SPLITS_DIR / 'X_test_17.parquet')\n",
    "\n",
    "    # Las 'y' originales vienen del split final (03.1)\n",
    "    y_train = pd.read_parquet(FINAL_SPLITS_DIR / 'y_train.parquet').squeeze()\n",
    "    y_val   = pd.read_parquet(FINAL_SPLITS_DIR / 'y_val.parquet').squeeze()\n",
    "    y_test  = pd.read_parquet(FINAL_SPLITS_DIR / 'y_test.parquet').squeeze()\n",
    "\n",
    "    print(\"Datos .parquet cargados correctamente.\")\n",
    "    print(\"\\n Shapes tras cargar splits:\")\n",
    "    print(f\"   • X_train_sint: {X_train_sint.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"   • X_val_sint:   {X_val_sint.shape},   y_val:   {y_val.shape}\")\n",
    "    print(f\"   • X_test_sint:  {X_test_sint.shape},  y_test:  {y_test.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n Ocurrió un error inesperado al cargar los datos: {e}\")\n",
    "    print(\"   Asegúrate de que los archivos 'X_..._17.parquet' existen en la carpeta 'data/splits/experiments'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TfXupNI9KtJ"
   },
   "source": [
    "## 3. Remapear etiquetas a dos clases y guardar resultados\n",
    "\n",
    "Define la función `remap_to_2` para convertir las etiquetas originales en dos clases binarias, aplica el remapeo a los conjuntos de entrenamiento, validación y prueba, muestra la distribución y guarda los nuevos archivos en `FINAL_SPLITS_DIR`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98,
     "status": "ok",
     "timestamp": 1749634193567,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "UpAiq5j72IwN",
    "outputId": "9911b5fa-f5b1-446c-8579-ea067ea86e92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución original (4 clases) en y_train:\n",
      "B10\n",
      "3.0    0.550101\n",
      "2.0    0.273279\n",
      "4.0    0.095142\n",
      "1.0    0.081478\n",
      "Name: proporción, dtype: float64\n",
      "\n",
      "Distribución binaria (2 clases) en y_train_2:\n",
      "B10\n",
      "1.0    0.645243\n",
      "0.0    0.354757\n",
      "Name: proporción, dtype: float64\n",
      "\n",
      "-----------------------------------------------\n",
      " Mapeo a 2 clases guardado correctamente.\n",
      "Archivos guardados en la carpeta: C:\\Users\\Antonio\\TFM-Digitech\\data\\splits\\final\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# REMAPEAR ETIQUETAS A 2 CLASES Y GUARDAR\n",
    "\n",
    "def remap_to_2(x):\n",
    "    if x in [1.0, 2.0]:\n",
    "        return 0.0 # Clase 0: Bajo/Medio Riesgo\n",
    "    else:\n",
    "        return 1.0 # Clase 1: Alto Riesgo\n",
    "\n",
    "y_train_2 = y_train.map(remap_to_2)\n",
    "y_val_2   = y_val.map(remap_to_2)\n",
    "y_test_2  = y_test.map(remap_to_2)\n",
    "\n",
    "print(\"\\nDistribución original (4 clases) en y_train:\")\n",
    "print(y_train.value_counts(normalize=True).rename(\"proporción\"))\n",
    "print(\"\\nDistribución binaria (2 clases) en y_train_2:\")\n",
    "print(y_train_2.value_counts(normalize=True).rename(\"proporción\"))\n",
    "\n",
    "y_train_2.to_frame().to_parquet(FINAL_SPLITS_DIR / 'y_train_2_classes.parquet')\n",
    "y_val_2.to_frame().to_parquet(FINAL_SPLITS_DIR / 'y_val_2_classes.parquet')\n",
    "y_test_2.to_frame().to_parquet(FINAL_SPLITS_DIR / 'y_test_2_classes.parquet')\n",
    "\n",
    "print(\"\\n-----------------------------------------------\")\n",
    "print(\" Mapeo a 2 clases guardado correctamente.\")\n",
    "print(f\"Archivos guardados en la carpeta: {FINAL_SPLITS_DIR}\")\n",
    "print(\"-----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1749634193610,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "yBpQ9ogL2ItO",
    "outputId": "6a21b4a0-2305-429a-9ff2-c4b12382790c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes para entrenamiento realista (sin SMOTE): (1976, 14) (1976,)\n",
      "Distribución en entrenamiento (sin SMOTE):\n",
      "B10\n",
      "1.0    0.645243\n",
      "0.0    0.354757\n",
      "Name: proporción, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "#    NO usar SMOTE para no alterar la distribución real.\n",
    "#    En su lugar, entrenaremos con `class_weight='balanced'`\n",
    "#    para que el modelo compense la clase minoritaria.\n",
    "# -------------------------------\n",
    "# (Simplemente dejamos las tablas X_train_sint, y_train_2 con proporción ≈35/65)\n",
    "\n",
    "print(\"\\nShapes para entrenamiento realista (sin SMOTE):\", X_train_sint.shape, y_train_2.shape)\n",
    "print(\"Distribución en entrenamiento (sin SMOTE):\")\n",
    "print(y_train_2.value_counts(normalize=True).rename(\"proporción\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzlvZ6cl9UF0"
   },
   "source": [
    "## 5. Definir pipelines de clasificación binaria\n",
    "\n",
    "Crea pipelines que combinan estandarización (`StandardScaler`) y clasificadores binarios (`LogisticRegression`, `RandomForestClassifier`, `GradientBoostingClassifier`) con manejo de `class_weight` cuando procede.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JGMCWpzB2IqJ"
   },
   "outputs": [],
   "source": [
    "# Definir pipelines binarios (estandarizar + clasificador con class_weight)\n",
    "\n",
    "# 1. Logistic Regression (binario, class_weight balanceado)\n",
    "pipe2_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(\n",
    "        solver='liblinear',\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2. Random Forest (binario, class_weight balanceado)\n",
    "pipe2_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        class_weight='balanced',\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 3. Gradient Boosting (binario)\n",
    "#     (GBM no soporta class_weight directamente, pero al validar sobre datos reales\n",
    "#      veremos su comportamiento; si se requiere, podríamos usar sample_weight)\n",
    "pipe2_gb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hbp0JHu9VuD"
   },
   "source": [
    "## 6. Entrenar modelos binarios sin SMOTE\n",
    "\n",
    "Entrena cada pipeline sobre el conjunto `X_train_sint` y las etiquetas `y_train_2` (sin aplicar SMOTE), e imprime el estado de entrenamiento de cada modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1749634194387,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "DStdIyn_2Ru4",
    "outputId": "2e73e346-a5c7-4b3b-ab9e-ee41ad06dd75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelos binarios (distribución real, sin SMOTE)...\n",
      " • LogisticRegression entrenada.\n",
      " • RandomForest entrenada.\n",
      " • GradientBoosting entrenada.\n"
     ]
    }
   ],
   "source": [
    "# Entrenar cada modelo sobre X_train_sint, y_train_2 (sin SMOTE)\n",
    "\n",
    "print(\"\\nEntrenando modelos binarios (distribución real, sin SMOTE)...\")\n",
    "\n",
    "pipe2_lr.fit(X_train_sint, y_train_2)\n",
    "print(\" • LogisticRegression entrenada.\")\n",
    "\n",
    "pipe2_rf.fit(X_train_sint, y_train_2)\n",
    "print(\" • RandomForest entrenada.\")\n",
    "\n",
    "pipe2_gb.fit(X_train_sint, y_train_2)\n",
    "print(\" • GradientBoosting entrenada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CE6lPLZk9Xb_"
   },
   "source": [
    "## 7. Ajustar umbrales de clasificación basados en validación\n",
    "\n",
    "Define funciones para optimizar el umbral de decisión tanto para la clase “alto riesgo” como para la clase “bajo riesgo” en el modelo `RandomForest`, y calcula ambos umbrales usando el conjunto de validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1749634194795,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "eMkyDc3R2RrV",
    "outputId": "06e4cf50-81c2-4683-acb7-dc261bcb00f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Threshold original para RF (maximizando F1 Alto Riesgo): 0.40, con F1_val: 0.8025\n",
      "→ NUEVO Threshold para RF (maximizando F1 Bajo Riesgo): 0.72, con F1_val: 0.5891\n"
     ]
    }
   ],
   "source": [
    "# Ajustar umbral para datos reales (opcional pero recomendado)\n",
    "\n",
    "# --- FUNCIÓN ORIGINAL: Optimiza para Clase 1 (Alto Riesgo) ---\n",
    "def find_best_threshold(pipe, X_val, y_val):\n",
    "    prob_val = pipe.predict_proba(X_val)[:,1]\n",
    "    best_t, best_f1 = 0.5, 0\n",
    "    for t in np.linspace(0.1, 0.9, 33):\n",
    "        yv_pred_t = (prob_val >= t).astype(int)\n",
    "        f1_t = f1_score(y_val, yv_pred_t, pos_label=1) # F1 para la clase 1\n",
    "        if f1_t > best_f1:\n",
    "            best_f1, best_t = f1_t, t\n",
    "    return best_t, best_f1\n",
    "\n",
    "# --- NUEVA FUNCIÓN: Optimiza para Clase 0 (Bajo Riesgo) ---\n",
    "def find_best_threshold_for_class_0(pipe, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Encuentra el umbral de probabilidad que maximiza el F1-Score para la CLASE 0.\n",
    "    Un umbral más alto hará que el modelo sea más 'estricto' para predecir la Clase 1,\n",
    "    protegiendo así a la Clase 0.\n",
    "    \"\"\"\n",
    "    prob_val = pipe.predict_proba(X_val)[:,1] # Probabilidades para la clase 1\n",
    "    best_t, best_f1_0 = 0.5, 0\n",
    "    # Buscamos en un rango amplio de umbrales\n",
    "    for t in np.linspace(0.1, 0.9, 81):\n",
    "        yv_pred_t = (prob_val >= t).astype(int)\n",
    "        # Calculamos el F1-Score específicamente para la clase 0 (pos_label=0)\n",
    "        f1_t_0 = f1_score(y_val, yv_pred_t, pos_label=0)\n",
    "        if f1_t_0 > best_f1_0:\n",
    "            best_f1_0, best_t = f1_t_0, t\n",
    "    return best_t, best_f1_0\n",
    "\n",
    "# --- CÁLCULO DE AMBOS UMBRALES ---\n",
    "\n",
    "# 1. Umbral original (maximizando F1 para Alto Riesgo)\n",
    "best_t_rf, best_f1_rf = find_best_threshold(pipe2_rf, X_val_sint, y_val_2)\n",
    "print(f\"→ Threshold original para RF (maximizando F1 Alto Riesgo): {best_t_rf:.2f}, con F1_val: {best_f1_rf:.4f}\")\n",
    "\n",
    "# 2. NUEVO umbral invertido (maximizando F1 para Bajo Riesgo)\n",
    "#    CORRECCIÓN: Usamos el pipeline 'pipe2_rf' que ya está definido y entrenado.\n",
    "best_t_rf_inverted, best_f1_rf_0 = find_best_threshold_for_class_0(pipe2_rf, X_val_sint, y_val_2)\n",
    "print(f\"→ NUEVO Threshold para RF (maximizando F1 Bajo Riesgo): {best_t_rf_inverted:.2f}, con F1_val: {best_f1_rf_0:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mp7NKt749Zdn"
   },
   "source": [
    "## 8. Definir función de evaluación binaria\n",
    "\n",
    "Implementa `evaluate_binary_realistic`, que evalúa un pipeline binario en validación y prueba, imprimiendo métricas clave (accuracy, F1, AUC) y mostrando las matrices de confusión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9KLMvK_S2Twm"
   },
   "outputs": [],
   "source": [
    "# Función de evaluación binaria (usando threshold = 0.5 o el óptimo encontrado)\n",
    "\n",
    "def evaluate_binary_realistic(pipe, X_val, y_val, X_test, y_test, name, threshold=0.5):\n",
    "    print(f\"\\n--- {name} sobre VALIDATION (2 clases, distrib real) ---\")\n",
    "    prob_val = pipe.predict_proba(X_val)[:,1]\n",
    "    yv_pred  = (prob_val >= threshold).astype(int)\n",
    "    print(f\"Threshold usado: {threshold:.2f}\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y_val, yv_pred):.4f}\")\n",
    "    print(f\"F1:        {f1_score(y_val, yv_pred):.4f}\")\n",
    "    print(f\"AUC:       {roc_auc_score(y_val, prob_val):.4f}\")\n",
    "    print(\"\\nClassification Report (val):\\n\", classification_report(y_val, yv_pred))\n",
    "    cm_val = confusion_matrix(y_val, yv_pred)\n",
    "    print(\"Confusion Matrix (val):\\n\", pd.DataFrame(cm_val,\n",
    "          index=['True 0','True 1'], columns=['Pred 0','Pred 1']))\n",
    "\n",
    "    print(f\"\\n--- {name} sobre TEST (2 clases, distrib real) ---\")\n",
    "    prob_test = pipe.predict_proba(X_test)[:,1]\n",
    "    yt_pred   = (prob_test >= threshold).astype(int)\n",
    "    print(f\"Threshold usado: {threshold:.2f}\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y_test, yt_pred):.4f}\")\n",
    "    print(f\"F1:        {f1_score(y_test, yt_pred):.4f}\")\n",
    "    print(f\"AUC:       {roc_auc_score(y_test, prob_test):.4f}\")\n",
    "    print(\"\\nClassification Report (test):\\n\", classification_report(y_test, yt_pred))\n",
    "    cm_test = confusion_matrix(y_test, yt_pred)\n",
    "    print(\"Confusion Matrix (test):\\n\", pd.DataFrame(cm_test,\n",
    "          index=['True 0','True 1'], columns=['Pred 0','Pred 1']))\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zjEp3Sv9beR"
   },
   "source": [
    "## 9. Evaluar y comparar modelos\n",
    "\n",
    "Ejecuta la evaluación de los modelos básicos y compara dos estrategias de umbral para `RandomForest` (detector de alto riesgo vs. protector de bajo riesgo), mostrando los resultados en consola.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1749634194996,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "I9K3GdiO2Tsz",
    "outputId": "ba4dadb1-542a-4cd8-f115-fab5a789153c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ANÁLISIS DE MODELOS BASE ---\n",
      "\n",
      "--- LogisticRegression2 sobre VALIDATION (2 clases, distrib real) ---\n",
      "Threshold usado: 0.50\n",
      "Accuracy:  0.6863\n",
      "F1:        0.7532\n",
      "AUC:       0.7304\n",
      "\n",
      "Classification Report (val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.59      0.57       150\n",
      "         1.0       0.77      0.74      0.75       274\n",
      "\n",
      "    accuracy                           0.69       424\n",
      "   macro avg       0.66      0.66      0.66       424\n",
      "weighted avg       0.69      0.69      0.69       424\n",
      "\n",
      "Confusion Matrix (val):\n",
      "         Pred 0  Pred 1\n",
      "True 0      88      62\n",
      "True 1      71     203\n",
      "\n",
      "--- LogisticRegression2 sobre TEST (2 clases, distrib real) ---\n",
      "Threshold usado: 0.50\n",
      "Accuracy:  0.6651\n",
      "F1:        0.7321\n",
      "AUC:       0.6855\n",
      "\n",
      "Classification Report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.59      0.55       150\n",
      "         1.0       0.76      0.71      0.73       274\n",
      "\n",
      "    accuracy                           0.67       424\n",
      "   macro avg       0.64      0.65      0.64       424\n",
      "weighted avg       0.68      0.67      0.67       424\n",
      "\n",
      "Confusion Matrix (test):\n",
      "         Pred 0  Pred 1\n",
      "True 0      88      62\n",
      "True 1      80     194\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- GradientBoosting2 sobre VALIDATION (2 clases, distrib real) ---\n",
      "Threshold usado: 0.50\n",
      "Accuracy:  0.7170\n",
      "F1:        0.8052\n",
      "AUC:       0.7034\n",
      "\n",
      "Classification Report (val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.37      0.48       150\n",
      "         1.0       0.73      0.91      0.81       274\n",
      "\n",
      "    accuracy                           0.72       424\n",
      "   macro avg       0.70      0.64      0.64       424\n",
      "weighted avg       0.71      0.72      0.69       424\n",
      "\n",
      "Confusion Matrix (val):\n",
      "         Pred 0  Pred 1\n",
      "True 0      56      94\n",
      "True 1      26     248\n",
      "\n",
      "--- GradientBoosting2 sobre TEST (2 clases, distrib real) ---\n",
      "Threshold usado: 0.50\n",
      "Accuracy:  0.6769\n",
      "F1:        0.7750\n",
      "AUC:       0.7134\n",
      "\n",
      "Classification Report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.34      0.43       150\n",
      "         1.0       0.70      0.86      0.78       274\n",
      "\n",
      "    accuracy                           0.68       424\n",
      "   macro avg       0.64      0.60      0.60       424\n",
      "weighted avg       0.66      0.68      0.65       424\n",
      "\n",
      "Confusion Matrix (test):\n",
      "         Pred 0  Pred 1\n",
      "True 0      51      99\n",
      "True 1      38     236\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "--- ANÁLISIS COMPARATIVO DE ESTRATEGIAS PARA RANDOMFOREST ---\n",
      "\n",
      "--- Estrategia Original: 'Detector de Alto Riesgo' ---\n",
      "\n",
      "--- RandomForest2 (Detector) sobre VALIDATION (2 clases, distrib real) ---\n",
      "Threshold usado: 0.40\n",
      "Accuracy:  0.6958\n",
      "F1:        0.8025\n",
      "AUC:       0.7105\n",
      "\n",
      "Classification Report (val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.22      0.34       150\n",
      "         1.0       0.69      0.96      0.80       274\n",
      "\n",
      "    accuracy                           0.70       424\n",
      "   macro avg       0.71      0.59      0.57       424\n",
      "weighted avg       0.71      0.70      0.64       424\n",
      "\n",
      "Confusion Matrix (val):\n",
      "         Pred 0  Pred 1\n",
      "True 0      33     117\n",
      "True 1      12     262\n",
      "\n",
      "--- RandomForest2 (Detector) sobre TEST (2 clases, distrib real) ---\n",
      "Threshold usado: 0.40\n",
      "Accuracy:  0.6863\n",
      "F1:        0.7969\n",
      "AUC:       0.6911\n",
      "\n",
      "Classification Report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.20      0.31       150\n",
      "         1.0       0.69      0.95      0.80       274\n",
      "\n",
      "    accuracy                           0.69       424\n",
      "   macro avg       0.69      0.58      0.55       424\n",
      "weighted avg       0.69      0.69      0.62       424\n",
      "\n",
      "Confusion Matrix (test):\n",
      "         Pred 0  Pred 1\n",
      "True 0      30     120\n",
      "True 1      13     261\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Estrategia Nueva: 'Protector de Bajo Riesgo' (SELECCIONADA) ---\n",
      "\n",
      "--- RandomForest2 (Protector) sobre VALIDATION (2 clases, distrib real) ---\n",
      "Threshold usado: 0.72\n",
      "Accuracy:  0.6085\n",
      "F1:        0.6261\n",
      "AUC:       0.7105\n",
      "\n",
      "Classification Report (val):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.79      0.59       150\n",
      "         1.0       0.82      0.51      0.63       274\n",
      "\n",
      "    accuracy                           0.61       424\n",
      "   macro avg       0.64      0.65      0.61       424\n",
      "weighted avg       0.69      0.61      0.61       424\n",
      "\n",
      "Confusion Matrix (val):\n",
      "         Pred 0  Pred 1\n",
      "True 0     119      31\n",
      "True 1     135     139\n",
      "\n",
      "--- RandomForest2 (Protector) sobre TEST (2 clases, distrib real) ---\n",
      "Threshold usado: 0.72\n",
      "Accuracy:  0.5896\n",
      "F1:        0.6167\n",
      "AUC:       0.6911\n",
      "\n",
      "Classification Report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.73      0.56       150\n",
      "         1.0       0.78      0.51      0.62       274\n",
      "\n",
      "    accuracy                           0.59       424\n",
      "   macro avg       0.61      0.62      0.59       424\n",
      "weighted avg       0.66      0.59      0.60       424\n",
      "\n",
      "Confusion Matrix (test):\n",
      "         Pred 0  Pred 1\n",
      "True 0     110      40\n",
      "True 1     134     140\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluar todos los modelos y comparar estrategias de RandomForest\n",
    "\n",
    "print(\"--- ANÁLISIS DE MODELOS BASE ---\")\n",
    "# Evaluación de Logistic Regression (sin cambios)\n",
    "evaluate_binary_realistic(pipe2_lr, X_val_sint, y_val_2, X_test_sint, y_test_2,\n",
    "                         name='LogisticRegression2', threshold=0.5)\n",
    "\n",
    "# Evaluación de Gradient Boosting (sin cambios)\n",
    "evaluate_binary_realistic(pipe2_gb, X_val_sint, y_val_2, X_test_sint, y_test_2,\n",
    "                         name='GradientBoosting2', threshold=0.5)\n",
    "\n",
    "\n",
    "print(\"\\n\\n--- ANÁLISIS COMPARATIVO DE ESTRATEGIAS PARA RANDOMFOREST ---\")\n",
    "# --- Estrategia 1: Maximizar la detección de ALTO RIESGO ---\n",
    "print(\"\\n--- Estrategia Original: 'Detector de Alto Riesgo' ---\")\n",
    "evaluate_binary_realistic(pipe2_rf, X_val_sint, y_val_2, X_test_sint, y_test_2,\n",
    "                         name='RandomForest2 (Detector)', threshold=best_t_rf)\n",
    "\n",
    "\n",
    "# --- Estrategia 2: Minimizar el error en BAJO RIESGO ---\n",
    "print(\"\\n--- Estrategia Nueva: 'Protector de Bajo Riesgo' (SELECCIONADA) ---\")\n",
    "evaluate_binary_realistic(pipe2_rf, X_val_sint, y_val_2, X_test_sint, y_test_2,\n",
    "                         name='RandomForest2 (Protector)', threshold=best_t_rf_inverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "It6vfDEXkWjN"
   },
   "source": [
    "## Conclusiones Finales\n",
    "- La **Regresión Logística** con umbral fijo (0.5) sirve de baseline estable, pero presenta limitaciones en recall de la clase minoritaria.  \n",
    "- **Gradient Boosting** mejora ligeramente el AUC general frente a LR, aunque no supera a Random Forest en balance de clases.  \n",
    "- **Random Forest + umbral “Protector de Bajo Riesgo”** logra el mejor compromiso global, reduciendo falsos positivos de alto riesgo y minimizando errores en detección de bajo riesgo.  \n",
    "- La estrategia “Detector de Alto Riesgo” aumenta recall de la clase alta pero eleva los falsos negativos de la clase baja, haciendo trade-off inadecuado para este caso.  \n",
    "- La optimización de umbrales basada en validación es esencial para ajustar el comportamiento del modelo a objetivos de negocio y riesgo financiero.  \n",
    "- Los thresholds calculados (`best_t_rf` y su inverso) confirman que apartarse de 0.5 mejora las métricas en escenarios realistas.  \n",
    "- El pipeline final recomendado es **Random Forest con threshold invertido** (“Protector de Bajo Riesgo”), por su capacidad de controlar errores de clasificación críticos.  \n",
    "- Este enfoque de evaluación realista y ajuste de umbral sienta una base sólida para el despliegue de clasificadores en entornos financieros sensibles.  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM0p5hSl2R5hEpK+VJV29VP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (TFM_Final)",
   "language": "python",
   "name": "venv_tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
