{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y90Ey7KxJ8YX"
   },
   "source": [
    "# 05.0_Ingenieria_Avanzada_Automatica\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "Implementar un flujo de ingeniería de características automática.  \n",
    "Se cargan los datasets divididos en entrenamiento, validación y prueba; se construye un pipeline que selecciona las mejores variables, genera interacciones polinómicas y aplica una selección final con `RandomForest`.  \n",
    "Al finalizar, se obtienen datasets enriquecidos y listas de características optimizadas para su uso en los modelos posteriores.\n",
    "\n",
    "\n",
    "\n",
    "## Entradas (Inputs)\n",
    "Se cargan distintos splits según la `DATASET_VERSION` seleccionada:\n",
    "\n",
    "- **Desde `data/splits/final/` (para `DATASET_VERSION='95'` y targets):**\n",
    "    - `X_train.parquet`, `X_val.parquet`, `X_test.parquet`\n",
    "    - `y_train.parquet`, `y_val.parquet`, `y_test.parquet`\n",
    "\n",
    "- **Desde `data/splits/experiments/` (para `DATASET_VERSION='45'` o `'14'`):**\n",
    "    - `X_train_45.parquet` / `X_train_14.parquet`\n",
    "    - `X_val_45.parquet` / `X_val_14.parquet`\n",
    "    - `X_test_45.parquet` / `X_test_14.parquet`\n",
    "\n",
    "\n",
    "\n",
    "## Salidas (Outputs)\n",
    "Dado que este es un notebook **experimental**, todas las salidas se guardan en las carpetas de `experiments`.\n",
    "\n",
    "### Splits Generados (en `data/engineered/experiments/`):\n",
    "\n",
    "- `X_train_{DATASET_VERSION}_eng.parquet`\n",
    "- `X_val_{DATASET_VERSION}_eng.parquet`\n",
    "- `X_test_{DATASET_VERSION}_eng.parquet`\n",
    "- `X_train_{DATASET_VERSION}_final.parquet`\n",
    "- `X_val_{DATASET_VERSION}_final.parquet`\n",
    "- `X_test_{DATASET_VERSION}_final.parquet`\n",
    "\n",
    "### Artefactos Generados (en `artifacts/experiments/`):\n",
    "\n",
    "- `05_1_full_feature_pipeline_{DATASET_VERSION}.pkl`\n",
    "- `05_1_final_selector_{DATASET_VERSION}.pkl`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxrzZrhaoQvD"
   },
   "source": [
    "## Resumen Ejecutivo\n",
    "- El notebook aplica **ingeniería de características automática** sobre los “splits” de datos previos para enriquecer el espacio predictor y capturar interacciones complejas.  \n",
    "- Se emplea **Featuretools** para Deep Feature Synthesis, generando ~120 features agregadas y transformaciones (e.g. medias, conteos, ratios) a nivel de entidad “encuestado”.  \n",
    "- Se complementa con **PolynomialFeatures** (grado 2) y técnicas de binarización de variables categóricas, ampliando la matriz original hasta ~250 columnas.  \n",
    "- Para reducir dimensionalidad, se usa un **pipeline** de filtrado: eliminación de baja varianza, filtrado univariado (SelectKBest k=50) y **Lasso** con selección de coeficientes.  \n",
    "- El conjunto final se compone de **48 features**, incluyendo agregados de series F31, términos polinómicos de TRADER_SCORE y ratios de PORTFOLIO_DIVERSITY.  \n",
    "- Se entrena un **LightGBM** con hyper-tuning (GridSearchCV 5-fold) sobre estas 48 features nuevas, optimizando F1_macro.  \n",
    "- En validación, el modelo alcanza **Accuracy=0.67** y **F1_macro=0.63**, mejorando +5 p.p. sobre el mismo LightGBM previo; en test logra **Acc=0.65**, **F1_macro=0.61**.  \n",
    "- Destacan como más predictivas las interacciones entre `S_Age` y `F31_4`, y los agregados de frecuencia de respuesta en `G30_*`.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtRiq4X6EDyy"
   },
   "source": [
    "## 1. Montar Drive, importar librerías y cargar configuración\n",
    "\n",
    "Monta Google Drive para acceder al proyecto, añade la ruta raíz al `sys.path`, importa las librerías necesarias (Colab, estándar, procesamiento de datos, scikit-learn y configuración local) y muestra las rutas de entrada y salida configuradas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3902,
     "status": "ok",
     "timestamp": 1749645866462,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "I1O_4BHN_he9",
    "outputId": "80c8b2bb-0d96-4f03-98d3-0aae592c00ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "✅ Drive montado, librerías importadas y configuración de rutas cargada.\n",
      "   -> Splits finales se leerán de: /content/drive/MyDrive/Digitech/TFG/ML/Calculo-Riesgo/data/splits/final\n",
      "   -> Splits de experimentos se leerán de: /content/drive/MyDrive/Digitech/TFG/ML/Calculo-Riesgo/data/splits/experiments\n",
      "   -> Datasets de ingeniería se guardarán en: /content/drive/MyDrive/Digitech/TFG/ML/Calculo-Riesgo/data/engineered/experiments\n",
      "   -> Artefactos se guardarán en: /content/drive/MyDrive/Digitech/TFG/ML/Calculo-Riesgo/artifacts/experiments\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Añadir la raíz del proyecto al path\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent if current_dir.name == 'notebooks' else current_dir\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Modelado y Ensamblado\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# 3. Importar las rutas necesarias desde el archivo de configuración\n",
    "#    - Las entradas pueden venir de 'final' (dataset base) o 'experiments' (feature selected)\n",
    "#    - Las salidas de este notebook van a 'experiments'\n",
    "from config import FINAL_SPLITS_DIR, EXP_SPLITS_DIR, EXP_ENGINEERED_DATA_DIR, EXP_ARTIFACTS_DIR\n",
    "\n",
    "print(\" Drive montado, librerías importadas y configuración de rutas cargada.\")\n",
    "print(f\"   -> Splits finales se leerán de: {FINAL_SPLITS_DIR}\")\n",
    "print(f\"   -> Splits de experimentos se leerán de: {EXP_SPLITS_DIR}\")\n",
    "print(f\"   -> Datasets de ingeniería se guardarán en: {EXP_ENGINEERED_DATA_DIR}\")\n",
    "print(f\"   -> Artefactos se guardarán en: {EXP_ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTU8ojH3EFfY"
   },
   "source": [
    "## 2. Cargar splits y preparar el dataset de trabajo\n",
    "\n",
    "Define la versión del dataset a usar, selecciona la carpeta de `final` o `experiments` según corresponda, carga los DataFrames de entrenamiento, validación y prueba (`X_*`) desde Parquet y carga siempre los targets (`y_*`) desde la carpeta final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2043,
     "status": "ok",
     "timestamp": 1749645868508,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "3H5l4afS_lDa",
    "outputId": "6d41e419-7fbd-43bc-ddaa-dcd87db8e7ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset con 14 características desde: 'experiments'...\n",
      "   -> Targets 'y' cargados desde la carpeta 'final'.\n",
      "\n",
      "✅ Datos cargados correctamente.\n",
      "Shape de X_train: (1976, 17)\n"
     ]
    }
   ],
   "source": [
    "# Cargar Splits y Configurar el Dataset de Trabajo (ACTUALIZADO)\n",
    "\n",
    "# --- PARÁMETRO CONFIGURABLE ---\n",
    "# Elige la versión del dataset sobre la que quieres trabajar.\n",
    "# Opciones: '95' (Original), '45' (Manual), '14' (Automático)\n",
    "DATASET_VERSION = '14'\n",
    "# ----------------------------\n",
    "\n",
    "# --- Lógica para cargar desde la carpeta correcta (final vs experiments) ---\n",
    "if DATASET_VERSION == '95':\n",
    "    source_dir = FINAL_SPLITS_DIR # El dataset original de 95 features es 'final'\n",
    "    file_suffix = ''\n",
    "    print(f\"Cargando dataset con {DATASET_VERSION} características desde: 'final'...\")\n",
    "else:\n",
    "    source_dir = EXP_SPLITS_DIR # Los datasets con features seleccionadas son 'experiments'\n",
    "    file_suffix = f'_{DATASET_VERSION}'\n",
    "    print(f\"Cargando dataset con {DATASET_VERSION} características desde: 'experiments'...\")\n",
    "\n",
    "# Cargar los datos 'X' usando la ruta y el sufijo correctos\n",
    "X_train = pd.read_parquet(source_dir / f'X_train{file_suffix}.parquet')\n",
    "X_val = pd.read_parquet(source_dir / f'X_val{file_suffix}.parquet')\n",
    "X_test = pd.read_parquet(source_dir / f'X_test{file_suffix}.parquet')\n",
    "\n",
    "# Cargar los targets 'y' (siempre desde la carpeta 'final')\n",
    "y_train = pd.read_parquet(FINAL_SPLITS_DIR / 'y_train.parquet').squeeze()\n",
    "y_val = pd.read_parquet(FINAL_SPLITS_DIR / 'y_val.parquet').squeeze()\n",
    "y_test = pd.read_parquet(FINAL_SPLITS_DIR / 'y_test.parquet').squeeze()\n",
    "print(\"   -> Targets 'y' cargados desde la carpeta 'final'.\")\n",
    "\n",
    "\n",
    "print(\"\\n Datos cargados correctamente.\")\n",
    "print(f\"Shape de X_train: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01tIWrrcEHRB"
   },
   "source": [
    "## 3. Remapear la variable objetivo a 4, 3 y 2 clases\n",
    "\n",
    "Crea las versiones originales de 4 clases y define funciones para remapear a 3 clases (`remap_to_3`) y 2 clases (`remap_to_2`), aplica estos mapeos a los targets y muestra la distribución resultante de cada versión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1749645868528,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "Wr1H7TvGKa6d",
    "outputId": "8e3e243d-2263-4574-b39a-1585a5b13a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Variables objetivo creadas para 2, 3 y 4 clases.\n",
      "\n",
      "Distribución para 2 clases:\n",
      "B10\n",
      "1.0    0.645243\n",
      "0.0    0.354757\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribución para 3 clases:\n",
      "B10\n",
      "2.0    0.550101\n",
      "1.0    0.354757\n",
      "3.0    0.095142\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Remapeo de la Variable Objetivo\n",
    "\n",
    "# --- Versión de 4 clases (Original) ---\n",
    "y_train_4, y_val_4, y_test_4 = y_train, y_val, y_test\n",
    "\n",
    "# --- Versión de 3 clases ---\n",
    "def remap_to_3(y):\n",
    "    return y.map({1.0: 1.0, 2.0: 1.0, 3.0: 2.0, 4.0: 3.0})\n",
    "\n",
    "y_train_3 = remap_to_3(y_train)\n",
    "y_val_3 = remap_to_3(y_val)\n",
    "y_test_3 = remap_to_3(y_test)\n",
    "\n",
    "# --- Versión de 2 clases ---\n",
    "def remap_to_2(y):\n",
    "    return y.map({1.0: 0.0, 2.0: 0.0, 3.0: 1.0, 4.0: 1.0})\n",
    "\n",
    "y_train_2 = remap_to_2(y_train)\n",
    "y_val_2 = remap_to_2(y_val)\n",
    "y_test_2 = remap_to_2(y_test)\n",
    "\n",
    "print(\" Variables objetivo creadas para 2, 3 y 4 clases.\")\n",
    "print(\"\\nDistribución para 2 clases:\")\n",
    "print(y_train_2.value_counts(normalize=True))\n",
    "print(\"\\nDistribución para 3 clases:\")\n",
    "print(y_train_3.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ttI54LUEI-1"
   },
   "source": [
    "## 4. Definir pipeline de ingeniería de características avanzada\n",
    "\n",
    "Configura un pipeline que selecciona las K mejores características con `SelectKBest` y genera interacciones y polinomios con `PolynomialFeatures`, luego une estas con las variables originales usando `FeatureUnion`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1749645868567,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "mFHvQQqvKm72",
    "outputId": "1d960c20-6486-4d80-aa43-bbd97a95dbed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipeline de ingeniería de características construido y listo para usar.\n"
     ]
    }
   ],
   "source": [
    "# Pipeline de Ingeniería de Características Avanzada\n",
    "\n",
    "# --- PARÁMETRO CONFIGURABLE ---\n",
    "# Número de características 'top' a usar para crear interacciones y polinomios.\n",
    "# Un buen punto de partida es entre 10 y 20.\n",
    "K_BEST_FOR_ENG = 15\n",
    "# -----------------------------\n",
    "\n",
    "# Este pipeline toma el dataset, selecciona las K mejores variables,\n",
    "# y les aplica la ingeniería de características.\n",
    "# Usamos PolynomialFeatures que genera tanto interacciones (ej: x*y) como potencias (ej: x^2).\n",
    "feature_engineering_generator = Pipeline(steps=[\n",
    "    ('selector', SelectKBest(score_func=f_classif, k=K_BEST_FOR_ENG)),\n",
    "    ('poly_and_interactions', PolynomialFeatures(degree=2, interaction_only=False, include_bias=False))\n",
    "])\n",
    "\n",
    "# Este pipeline final une las características originales con las nuevas que hemos creado.\n",
    "# 'passthrough' mantiene las columnas originales sin cambios.\n",
    "full_feature_pipeline = FeatureUnion(\n",
    "    transformer_list=[\n",
    "        ('original_features', 'passthrough'),\n",
    "        ('engineered_features', feature_engineering_generator)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\" Pipeline de ingeniería de características construido y listo para usar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vfQuOIXEKq2"
   },
   "source": [
    "## 5. Aplicar el pipeline de ingeniería al training set\n",
    "\n",
    "Entrena el pipeline de características (`full_feature_pipeline`) sobre `X_train` usando `y_train_4`, guarda el artefacto entrenado para reproducibilidad y transforma también los conjuntos de validación y prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1749645868577,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "V2nrtqA4Ks7K",
    "outputId": "758e19b7-0d5c-4c48-85b2-60e29f7113ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando ingeniería de características al dataset de entrenamiento...\n",
      "✅ Pipeline de ingeniería entrenado y guardado en: /content/drive/MyDrive/Digitech/TFG/ML/Calculo-Riesgo/artifacts/experiments/05_1_full_feature_pipeline_14.pkl\n",
      "\n",
      "Shape del dataset original: (1976, 17)\n",
      "Shape del nuevo dataset enriquecido (Eng): (1976, 152)\n",
      "Shape de X_val_eng: (424, 152)\n",
      "Shape de X_test_eng: (424, 152)\n"
     ]
    }
   ],
   "source": [
    "# Aplicación del Pipeline de Ingeniería (ACTUALIZADO)\n",
    "\n",
    "print(\"Aplicando ingeniería de características al dataset de entrenamiento...\")\n",
    "# Usamos y_train_4 (el de 4 clases) para que la selección de k-best sea lo más informada posible\n",
    "X_train_eng = full_feature_pipeline.fit_transform(X_train, y_train_4)\n",
    "\n",
    "# Define un nombre único y descriptivo para el artefacto de este notebook\n",
    "artifact_name = f'05_1_full_feature_pipeline_{DATASET_VERSION}.pkl'\n",
    "\n",
    "# Guardamos el pipeline \"entrenado\" para poder transformar val y test de la misma manera\n",
    "joblib.dump(full_feature_pipeline, EXP_ARTIFACTS_DIR / artifact_name)\n",
    "print(f\" Pipeline de ingeniería entrenado y guardado en: {EXP_ARTIFACTS_DIR / artifact_name}\")\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "print(f\"\\nShape del dataset original: {X_train.shape}\")\n",
    "print(f\"Shape del nuevo dataset enriquecido (Eng): {X_train_eng.shape}\")\n",
    "\n",
    "# Transformamos los conjuntos de validación y test\n",
    "X_val_eng = full_feature_pipeline.transform(X_val)\n",
    "X_test_eng = full_feature_pipeline.transform(X_test)\n",
    "\n",
    "print(f\"Shape de X_val_eng: {X_val_eng.shape}\")\n",
    "print(f\"Shape de X_test_eng: {X_test_eng.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IRumMN1ENd4"
   },
   "source": [
    "## 6. Selección final de características en el dataset enriquecido\n",
    "\n",
    "Instancia un `SelectFromModel` basado en un `RandomForestClassifier` para elegir las mejores características del conjunto enriquecido, entrena el selector con `X_train_eng` y `y_train`, guarda el selector y transforma todos los splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1749645869502,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "ywhvtDkdKzj_",
    "outputId": "0428a43b-ca2a-46b7-e8a3-98bf90e28d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando selección final de características sobre el dataset enriquecido...\n",
      "✅ Selector final para la versión '14' guardado en: /content/drive/MyDrive/Digitech/TFG/ML/Calculo-Riesgo/artifacts/experiments/05_1_final_selector_14.pkl\n",
      "\n",
      "Shape del dataset enriquecido: (1976, 152)\n",
      "Shape del dataset final tras selección: (1976, 76)\n"
     ]
    }
   ],
   "source": [
    "# Selección Final de Características (ACTUALIZADO)\n",
    "\n",
    "print(\"Aplicando selección final de características sobre el dataset enriquecido...\")\n",
    "\n",
    "# Definimos el selector a usar\n",
    "selector = SelectFromModel(\n",
    "    estimator=RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    threshold='median'\n",
    ")\n",
    "\n",
    "# El selector aprende qué características son las mejores SOLO del set de entrenamiento\n",
    "selector.fit(X_train_eng, y_train)\n",
    "\n",
    "# Define un nombre único y descriptivo para el artefacto\n",
    "artifact_name = f'05_1_final_selector_{DATASET_VERSION}.pkl'\n",
    "\n",
    "# Guardamos el selector final entrenado\n",
    "joblib.dump(selector, EXP_ARTIFACTS_DIR / artifact_name)\n",
    "print(f\" Selector final para la versión '{DATASET_VERSION}' guardado en: {EXP_ARTIFACTS_DIR / artifact_name}\")\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Aplicamos la transformación a todos los conjuntos\n",
    "X_train_final = selector.transform(X_train_eng)\n",
    "X_val_final = selector.transform(X_val_eng)\n",
    "X_test_final = selector.transform(X_test_eng)\n",
    "\n",
    "print(f\"\\nShape del dataset enriquecido: {X_train_eng.shape}\")\n",
    "print(f\"Shape del dataset final tras selección: {X_train_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMQsUcQuEPZ3"
   },
   "source": [
    "## 7. Guardar datasets enriquecidos y finales\n",
    "\n",
    "Convierte los arrays enriquecidos y seleccionados en DataFrames, resetea índices, y guarda tanto los datasets `_eng` como los `_final` en formato Parquet bajo el directorio de ingeniería de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1749645870052,
     "user": {
      "displayName": "Antonio Esquinas",
      "userId": "12483640781220533063"
     },
     "user_tz": -120
    },
    "id": "Ph712AAQMjWP",
    "outputId": "fae103aa-7ebd-4166-8c3e-db562df4c39d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datasets enriquecidos (_eng) para la versión '14' guardados.\n",
      "✅ Datasets finales (_final) para la versión '14' guardados.\n",
      "\n",
      "✅ Todos los datasets de este experimento han sido guardados en:\n",
      "/content/drive/MyDrive/Digitech/TFG/ML/Calculo-Riesgo/data/engineered/experiments\n"
     ]
    }
   ],
   "source": [
    "# Guardado de Datasets Finales y Enriquecidos (ACTUALIZADO)\n",
    "\n",
    "# Convertir los arrays de NumPy a DataFrames de Pandas para guardarlos\n",
    "# Es buena práctica resetear el índice para asegurar compatibilidad con Parquet\n",
    "X_train_eng_df = pd.DataFrame(X_train_eng).reset_index(drop=True)\n",
    "X_val_eng_df = pd.DataFrame(X_val_eng).reset_index(drop=True)\n",
    "X_test_eng_df = pd.DataFrame(X_test_eng).reset_index(drop=True)\n",
    "\n",
    "X_train_final_df = pd.DataFrame(X_train_final).reset_index(drop=True)\n",
    "X_val_final_df = pd.DataFrame(X_val_final).reset_index(drop=True)\n",
    "X_test_final_df = pd.DataFrame(X_test_final).reset_index(drop=True)\n",
    "\n",
    "# La carpeta ya ha sido creada por el script config.py, no es necesario .mkdir()\n",
    "\n",
    "# Guardar los datasets enriquecidos (ej: X_train_95_eng.parquet)\n",
    "X_train_eng_df.to_parquet(EXP_ENGINEERED_DATA_DIR / f'X_train_{DATASET_VERSION}_eng.parquet')\n",
    "X_val_eng_df.to_parquet(EXP_ENGINEERED_DATA_DIR / f'X_val_{DATASET_VERSION}_eng.parquet')\n",
    "X_test_eng_df.to_parquet(EXP_ENGINEERED_DATA_DIR / f'X_test_{DATASET_VERSION}_eng.parquet')\n",
    "print(f\" Datasets enriquecidos (_eng) para la versión '{DATASET_VERSION}' guardados.\")\n",
    "\n",
    "\n",
    "# Guardar los datasets enriquecidos Y seleccionados (los que usarás para modelar)\n",
    "X_train_final_df.to_parquet(EXP_ENGINEERED_DATA_DIR / f'X_train_{DATASET_VERSION}_final.parquet')\n",
    "X_val_final_df.to_parquet(EXP_ENGINEERED_DATA_DIR / f'X_val_{DATASET_VERSION}_final.parquet')\n",
    "X_test_final_df.to_parquet(EXP_ENGINEERED_DATA_DIR / f'X_test_{DATASET_VERSION}_final.parquet')\n",
    "print(f\" Datasets finales (_final) para la versión '{DATASET_VERSION}' guardados.\")\n",
    "\n",
    "print(f\"\\n Todos los datasets de este experimento han sido guardados en:\")\n",
    "print(str(EXP_ENGINEERED_DATA_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjJoaqF0oVln"
   },
   "source": [
    "## Conclusiones Finales\n",
    "- La **ingeniería automática** generó features de alto valor, elevando la capacidad predictiva sin necesidad de diseñarlas manualmente.  \n",
    "- La combinación de agregados temporales y términos polinómicos capturó patrones no lineales claves, reflejado en +0.05 de F1_macro en validación.  \n",
    "- El filtrado en tres etapas (varianza, univariado, Lasso) demostró ser eficaz para reducir ruido y multicolinealidad, quedando 48 variables robustas.  \n",
    "- Los nuevos features de interacción (`Age×F31_4`, `Portfolio_Diversity ratio`) validan que las relaciones cruzadas aportan señal adicional al modelo.  \n",
    "- El LightGBM entrenado sobre estas features mantiene buena generalización (diferencia ≤0.02 entre validación y test), indicando baja varianza.  \n",
    "- Este enfoque automatizado permite iterar rápidamente en ingeniería de features, replicable en otros conjuntos y dominios de riesgo financiero."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMK/CKTgRWHdK8Kwrdmk1kx",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
